code/8queens.m
Running code/8queens.m with MPI on [1] processes ... DONE!
Running code/8queens.m with MPI on [2] processes ... DONE!
Running code/8queens.m with MPI on [3] processes ... DONE!
Running code/8queens.m with MPI on [4] processes ... DONE!
Running code/8queens.m with MPI on [5] processes ... DONE!
code/all_pairs1.m
Running code/all_pairs1.m with MPI on [1] processes ... DONE!
Running code/all_pairs1.m with MPI on [2] processes ... DONE!
Running code/all_pairs1.m with MPI on [3] processes ... DONE!
Running code/all_pairs1.m with MPI on [4] processes ... DONE!
Running code/all_pairs1.m with MPI on [5] processes ... DONE!
code/all_pairs2.m
Running code/all_pairs2.m with MPI on [1] processes ... DONE!
Running code/all_pairs2.m with MPI on [2] processes ... DONE!
Running code/all_pairs2.m with MPI on [3] processes ... DONE!
Running code/all_pairs2.m with MPI on [4] processes ... DONE!
Running code/all_pairs2.m with MPI on [5] processes ... DONE!
code/bp1.m
Running code/bp1.m with MPI on [1] processes ... DONE!
Running code/bp1.m with MPI on [2] processes ... DONE!
Running code/bp1.m with MPI on [3] processes ... DONE!
Running code/bp1.m with MPI on [4] processes ... DONE!
Running code/bp1.m with MPI on [5] processes ... DONE!
code/dfs.m
Running code/dfs.m with MPI on [1] processes ... DONE!
Running code/dfs.m with MPI on [2] processes ... DONE!
Running code/dfs.m with MPI on [3] processes ... DONE!
Running code/dfs.m with MPI on [4] processes ... DONE!
Running code/dfs.m with MPI on [5] processes ... DONE!
code/linear-comp1.m
Running code/linear-comp1.m with MPI on [1] processes ... DONE!
Running code/linear-comp1.m with MPI on [2] processes ... DONE!
Running code/linear-comp1.m with MPI on [3] processes ... DONE!
Running code/linear-comp1.m with MPI on [4] processes ... DONE!
Running code/linear-comp1.m with MPI on [5] processes ... DONE!
code/linear-delete.m
Running code/linear-delete.m with MPI on [1] processes ... DONE!
Running code/linear-delete.m with MPI on [2] processes ... DONE!
Running code/linear-delete.m with MPI on [3] processes ... DONE!
Running code/linear-delete.m with MPI on [4] processes ... DONE!
Running code/linear-delete.m with MPI on [5] processes ... DONE!
code/linear-keep1.m
Running code/linear-keep1.m with MPI on [1] processes ... DONE!
Running code/linear-keep1.m with MPI on [2] processes ... DONE!
Running code/linear-keep1.m with MPI on [3] processes ... DONE!
Running code/linear-keep1.m with MPI on [4] processes ... DONE!
Running code/linear-keep1.m with MPI on [5] processes ... DONE!
code/linear-keep2.m
Running code/linear-keep2.m with MPI on [1] processes ... DONE!
Running code/linear-keep2.m with MPI on [2] processes ... DONE!
Running code/linear-keep2.m with MPI on [3] processes ... DONE!
Running code/linear-keep2.m with MPI on [4] processes ... DONE!
Running code/linear-keep2.m with MPI on [5] processes ... DONE!
code/linear-ref-use.m
Running code/linear-ref-use.m with MPI on [1] processes ... DONE!
Running code/linear-ref-use.m with MPI on [2] processes ... DONE!
Running code/linear-ref-use.m with MPI on [3] processes ... DONE!
Running code/linear-ref-use.m with MPI on [4] processes ... DONE!
Running code/linear-ref-use.m with MPI on [5] processes ... DONE!
code/linear-repeat.m
Running code/linear-repeat.m with MPI on [1] processes ... DONE!
Running code/linear-repeat.m with MPI on [2] processes ... DONE!
Running code/linear-repeat.m with MPI on [3] processes ... DONE!
Running code/linear-repeat.m with MPI on [4] processes ... DONE!
Running code/linear-repeat.m with MPI on [5] processes ... DONE!
code/linear-update1.m
Running code/linear-update1.m with MPI on [1] processes ... DONE!
Running code/linear-update1.m with MPI on [2] processes ... DONE!
Running code/linear-update1.m with MPI on [3] processes ... DONE!
Running code/linear-update1.m with MPI on [4] processes ... DONE!
Running code/linear-update1.m with MPI on [5] processes ... DONE!
code/linear-update2.m
Running code/linear-update2.m with MPI on [1] processes ... DONE!
Running code/linear-update2.m with MPI on [2] processes ... DONE!
Running code/linear-update2.m with MPI on [3] processes ... DONE!
Running code/linear-update2.m with MPI on [4] processes ... DONE!
Running code/linear-update2.m with MPI on [5] processes ... DONE!
code/linear-update3.m
Running code/linear-update3.m with MPI on [1] processes ... DONE!
Running code/linear-update3.m with MPI on [2] processes ... DONE!
Running code/linear-update3.m with MPI on [3] processes ... DONE!
Running code/linear-update3.m with MPI on [4] processes ... DONE!
Running code/linear-update3.m with MPI on [5] processes ... DONE!
code/list-floats.m
Running code/list-floats.m with MPI on [1] processes ... DONE!
Running code/list-floats.m with MPI on [2] processes ... DONE!
Running code/list-floats.m with MPI on [3] processes ... DONE!
Running code/list-floats.m with MPI on [4] processes ... DONE!
Running code/list-floats.m with MPI on [5] processes ... DONE!
code/mfp.m
Running code/mfp.m with MPI on [1] processes ... DONE!
Running code/mfp.m with MPI on [2] processes ...--- files/mfp.test	2013-05-23 16:30:49.000000000 -0400
+++ test.out	2013-07-14 22:05:55.000000000 -0400
@@ -6,45 +6,45 @@
 !edge(@1, 7, 0)
 !edge(@2, 15, 0)
 nbInitHeightMsgs(0)
-rv(@1, 7)
-rv(@2, 13)
-edge-height(@1, 3)
-edge-height(@2, 1)
+rv(@1, 5)
+rv(@2, 15)
+edge-height(@1, 1)
+edge-height(@2, 3)
 !outbound(0)
 token()
 1
 !typ(2)
 state(0)
-height(3)
+height(1)
 excess(0)
 !edge(@0, 7, 1)
 !edge(@2, 2, 0)
 !edge(@3, 11, 0)
 nbInitHeightMsgs(0)
-rv(@0, 0)
-rv(@2, 0)
-rv(@3, 7)
+rv(@0, 2)
+rv(@2, 2)
+rv(@3, 3)
 edge-height(@0, 0)
-edge-height(@2, 1)
+edge-height(@2, 3)
 edge-height(@3, 2)
 !outbound(1)
 token()
 2
 !typ(2)
 state(0)
-height(1)
+height(3)
 excess(0)
 !edge(@0, 15, 1)
 !edge(@1, 2, 1)
 !edge(@3, 10, 0)
 !edge(@4, 8, 0)
 nbInitHeightMsgs(0)
-rv(@0, 2)
-rv(@1, 2)
-rv(@3, 5)
+rv(@0, 0)
+rv(@1, 0)
+rv(@3, 9)
 rv(@4, 8)
 edge-height(@0, 0)
-edge-height(@1, 3)
+edge-height(@1, 1)
 edge-height(@3, 2)
 edge-height(@4, 7)
 !outbound(2)
@@ -59,12 +59,12 @@
 !edge(@4, 1, 0)
 !edge(@5, 11, 0)
 nbInitHeightMsgs(0)
-rv(@1, 4)
-rv(@2, 5)
+rv(@1, 8)
+rv(@2, 1)
 rv(@4, 1)
 rv(@5, 11)
-edge-height(@1, 3)
-edge-height(@2, 1)
+edge-height(@1, 1)
+edge-height(@2, 3)
 edge-height(@4, 7)
 edge-height(@5, 6)
 !outbound(2)
@@ -81,7 +81,7 @@
 rv(@2, 0)
 rv(@3, 0)
 rv(@5, 9)
-edge-height(@2, 1)
+edge-height(@2, 3)
 edge-height(@3, 2)
 edge-height(@5, 6)
 !outbound(2)
!!!!!! DIFFERENCES IN FILE code/mfp.m (mpiexec -n 2 ../meld -d -f code/mfp.m -c sl)
 DONE!
Running code/mfp.m with MPI on [3] processes ... DONE!
Running code/mfp.m with MPI on [4] processes ... DONE!
Running code/mfp.m with MPI on [5] processes ... DONE!
code/mwst.m
Running code/mwst.m with MPI on [1] processes ... DONE!
Running code/mwst.m with MPI on [2] processes ... DONE!
Running code/mwst.m with MPI on [3] processes ... DONE!
Running code/mwst.m with MPI on [4] processes ... DONE!
Running code/mwst.m with MPI on [5] processes ... DONE!
code/neural_network1.m
Running code/neural_network1.m with MPI on [1] processes ... DONE!
Running code/neural_network1.m with MPI on [2] processes ... DONE!
Running code/neural_network1.m with MPI on [3] processes ... DONE!
Running code/neural_network1.m with MPI on [4] processes ... DONE!
Running code/neural_network1.m with MPI on [5] processes ... DONE!
code/pagerank-linear-sync.m
Running code/pagerank-linear-sync.m with MPI on [1] processes ... DONE!
Running code/pagerank-linear-sync.m with MPI on [2] processes ... DONE!
Running code/pagerank-linear-sync.m with MPI on [3] processes ... DONE!
Running code/pagerank-linear-sync.m with MPI on [4] processes ... DONE!
Running code/pagerank-linear-sync.m with MPI on [5] processes ... DONE!
code/pagerank1.m
Running code/pagerank1.m with MPI on [1] processes ... DONE!
Running code/pagerank1.m with MPI on [2] processes ... DONE!
Running code/pagerank1.m with MPI on [3] processes ... DONE!
Running code/pagerank1.m with MPI on [4] processes ... DONE!
Running code/pagerank1.m with MPI on [5] processes ... DONE!
code/pagerank2.m
Running code/pagerank2.m with MPI on [1] processes ... DONE!
Running code/pagerank2.m with MPI on [2] processes ... DONE!
Running code/pagerank2.m with MPI on [3] processes ... DONE!
Running code/pagerank2.m with MPI on [4] processes ... DONE!
Running code/pagerank2.m with MPI on [5] processes ... DONE!
code/right_connectivity1.m
Running code/right_connectivity1.m with MPI on [1] processes ... DONE!
Running code/right_connectivity1.m with MPI on [2] processes ... DONE!
Running code/right_connectivity1.m with MPI on [3] processes ... DONE!
Running code/right_connectivity1.m with MPI on [4] processes ... DONE!
Running code/right_connectivity1.m with MPI on [5] processes ... DONE!
code/shortest_path1.m
Running code/shortest_path1.m with MPI on [1] processes ... DONE!
Running code/shortest_path1.m with MPI on [2] processes ... DONE!
Running code/shortest_path1.m with MPI on [3] processes ... DONE!
Running code/shortest_path1.m with MPI on [4] processes ... DONE!
Running code/shortest_path1.m with MPI on [5] processes ... DONE!
code/shortest_path2.m
Running code/shortest_path2.m with MPI on [1] processes ... DONE!
Running code/shortest_path2.m with MPI on [2] processes ... DONE!
Running code/shortest_path2.m with MPI on [3] processes ... DONE!
Running code/shortest_path2.m with MPI on [4] processes ... DONE!
Running code/shortest_path2.m with MPI on [5] processes ... DONE!
code/visit.m
Running code/visit.m with MPI on [1] processes ... DONE!
Running code/visit.m with MPI on [2] processes ... DONE!
Running code/visit.m with MPI on [3] processes ... DONE!
Running code/visit.m with MPI on [4] processes ... DONE!
Running code/visit.m with MPI on [5] processes ... DONE!
